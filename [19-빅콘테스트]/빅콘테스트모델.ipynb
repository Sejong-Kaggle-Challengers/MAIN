{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "빅콘테스트시도.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRDiDHWApNND",
        "outputId": "e45721a7-164f-4b54-e58a-cebe832c3c4a"
      },
      "source": [
        "!unzip -O 'cp949' \"2021 빅콘테스트_데이터분석분야_퓨처스리그_홍수ZERO_데이터_210803.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  2021 빅콘테스트_데이터분석분야_퓨처스리그_홍수ZERO_데이터_210803.zip\n",
            "   creating: 2021 빅콘테스트_데이터분석분야_퓨처스리그_홍수ZERO_데이터_210803/01_제공데이터/\n",
            "  inflating: 2021 빅콘테스트_데이터분석분야_퓨처스리그_홍수ZERO_데이터_210803/01_제공데이터/2021 빅콘테스트_데이터분석분야_퓨처스리그_홍수ZERO_댐유입량,강우,수위데이터_210803.xlsx  \n",
            "   creating: 2021 빅콘테스트_데이터분석분야_퓨처스리그_홍수ZERO_데이터_210803/02_평가데이터/\n",
            "  inflating: 2021 빅콘테스트_데이터분석분야_퓨처스리그_홍수ZERO_데이터_210803/02_평가데이터/2021 빅콘테스트_데이터분석분야_퓨처스리그_홍수ZERO_평가데이터_210803.xlsx  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COGel5SDp_B2"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime,timedelta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2oQsGteqNVU"
      },
      "source": [
        "## 공통\n",
        "base='2021 빅콘테스트_데이터분석분야_퓨처스리그_홍수ZERO_데이터_210803/'\n",
        "train_folder='01_제공데이터/'\n",
        "\n",
        "data=pd.read_excel(base+train_folder+'2021 빅콘테스트_데이터분석분야_퓨처스리그_홍수ZERO_댐유입량,강우,수위데이터_210803.xlsx')\n",
        "\n",
        "cols=['홍수사상번호','연','월','일','시간','유입량']\n",
        "\n",
        "for i in range(1,7):\n",
        "    prefix=f'데이터집단{i}_'\n",
        "    cols.append(prefix+'유역평균강수')\n",
        "    cols.append(prefix+'강우(A지역)')\n",
        "    cols.append(prefix+'강우(B지역)')\n",
        "    cols.append(prefix+'강우(C지역)')\n",
        "    cols.append(prefix+'강우(D지역)')\n",
        "    cols.append(prefix+'수위(E지역)')\n",
        "    cols.append(prefix+'수위(B지역)')\n",
        "\n",
        "data=data.drop(0).reset_index(drop=True)\n",
        "data.columns=cols\n",
        "\n",
        "for idx,col in enumerate(cols):\n",
        "    if idx<5:\n",
        "        data[col]=data[col].astype(int)\n",
        "    else:\n",
        "        data[col]=data[col].astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulh7YIEZvf33"
      },
      "source": [
        "## reproducibility\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "seed=71\n",
        "\n",
        "def seedEvery(seed):\n",
        "    os.environ['PYTHONHASHSEED']=str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    \n",
        "seedEvery(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fYz6xWiKZOE"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error \n",
        "from sklearn.model_selection import train_test_split    \n",
        "        \n",
        "from datetime import datetime,timedelta\n",
        "\n",
        "data['time']=data.apply(lambda row:datetime(year=int(row['연']),month=int(row['월']),day=int(row['일'])),axis=1)\n",
        "data['time']=data.apply(lambda row:row['time']+timedelta(hours=row['시간']),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDj0c-COKdTQ",
        "outputId": "cd0a9382-fc60-4176-9b72-bd004ac3ea08"
      },
      "source": [
        "## 빅콘테스트 수정사항\n",
        "data.loc[2199,'홍수사상번호']=20\n",
        "data=data.sort_values(by=['홍수사상번호','time']).reset_index(drop=True)\n",
        "\n",
        "test=data.iloc[2891:]\n",
        "\n",
        "submit=test[['홍수사상번호','연','월','일','시간']]\n",
        "submit['유입량']=0\n",
        "\n",
        "data=data.drop(['연','월','일','시간'],axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPM8n81jKiRT"
      },
      "source": [
        "## 유입량 < 10000\n",
        "idx2=data[data['홍수사상번호']==1].loc[data['유입량']>=10000].index\n",
        "data=data.drop(idx2,axis=0).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FZhFQN7KlWd"
      },
      "source": [
        "## lag 변수\n",
        "lag_3=data.set_index('time').groupby('홍수사상번호')[[col for col in data.columns if '강우' in col]].shift(3).reset_index().fillna(method='bfill')\n",
        "\n",
        "lag_3.columns=['time']+['lag3_'+col for col in lag_3.columns[1:]]\n",
        "\n",
        "data=pd.merge(data,lag_3,on='time',how='left')\n",
        "data=data.drop(['time'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "nQYc2Ig7KooJ",
        "outputId": "f33444c3-16b3-4f94-cea8-f60b108cad3c"
      },
      "source": [
        "## 정규화\n",
        "## 나중에 예측값 내고. (pred+mean)*std 하기.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "for col in data.columns[1:]:\n",
        "    if col=='유입량':\n",
        "        mean=data[col].mean()\n",
        "        std=data[col].std()\n",
        "        data[col]=(data[col]-mean)/std\n",
        "        continue\n",
        "    ss=StandardScaler()\n",
        "    data[col]=ss.fit_transform(data[col].values.reshape(-1,1))\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>홍수사상번호</th>\n",
              "      <th>유입량</th>\n",
              "      <th>데이터집단1_유역평균강수</th>\n",
              "      <th>데이터집단1_강우(A지역)</th>\n",
              "      <th>데이터집단1_강우(B지역)</th>\n",
              "      <th>데이터집단1_강우(C지역)</th>\n",
              "      <th>데이터집단1_강우(D지역)</th>\n",
              "      <th>데이터집단1_수위(E지역)</th>\n",
              "      <th>데이터집단1_수위(B지역)</th>\n",
              "      <th>데이터집단2_유역평균강수</th>\n",
              "      <th>데이터집단2_강우(A지역)</th>\n",
              "      <th>데이터집단2_강우(B지역)</th>\n",
              "      <th>데이터집단2_강우(C지역)</th>\n",
              "      <th>데이터집단2_강우(D지역)</th>\n",
              "      <th>데이터집단2_수위(E지역)</th>\n",
              "      <th>데이터집단2_수위(B지역)</th>\n",
              "      <th>데이터집단3_유역평균강수</th>\n",
              "      <th>데이터집단3_강우(A지역)</th>\n",
              "      <th>데이터집단3_강우(B지역)</th>\n",
              "      <th>데이터집단3_강우(C지역)</th>\n",
              "      <th>데이터집단3_강우(D지역)</th>\n",
              "      <th>데이터집단3_수위(E지역)</th>\n",
              "      <th>데이터집단3_수위(B지역)</th>\n",
              "      <th>데이터집단4_유역평균강수</th>\n",
              "      <th>데이터집단4_강우(A지역)</th>\n",
              "      <th>데이터집단4_강우(B지역)</th>\n",
              "      <th>데이터집단4_강우(C지역)</th>\n",
              "      <th>데이터집단4_강우(D지역)</th>\n",
              "      <th>데이터집단4_수위(E지역)</th>\n",
              "      <th>데이터집단4_수위(B지역)</th>\n",
              "      <th>데이터집단5_유역평균강수</th>\n",
              "      <th>데이터집단5_강우(A지역)</th>\n",
              "      <th>데이터집단5_강우(B지역)</th>\n",
              "      <th>데이터집단5_강우(C지역)</th>\n",
              "      <th>데이터집단5_강우(D지역)</th>\n",
              "      <th>데이터집단5_수위(E지역)</th>\n",
              "      <th>데이터집단5_수위(B지역)</th>\n",
              "      <th>데이터집단6_유역평균강수</th>\n",
              "      <th>데이터집단6_강우(A지역)</th>\n",
              "      <th>데이터집단6_강우(B지역)</th>\n",
              "      <th>데이터집단6_강우(C지역)</th>\n",
              "      <th>데이터집단6_강우(D지역)</th>\n",
              "      <th>데이터집단6_수위(E지역)</th>\n",
              "      <th>데이터집단6_수위(B지역)</th>\n",
              "      <th>lag3_데이터집단1_강우(A지역)</th>\n",
              "      <th>lag3_데이터집단1_강우(B지역)</th>\n",
              "      <th>lag3_데이터집단1_강우(C지역)</th>\n",
              "      <th>lag3_데이터집단1_강우(D지역)</th>\n",
              "      <th>lag3_데이터집단2_강우(A지역)</th>\n",
              "      <th>lag3_데이터집단2_강우(B지역)</th>\n",
              "      <th>lag3_데이터집단2_강우(C지역)</th>\n",
              "      <th>lag3_데이터집단2_강우(D지역)</th>\n",
              "      <th>lag3_데이터집단3_강우(A지역)</th>\n",
              "      <th>lag3_데이터집단3_강우(B지역)</th>\n",
              "      <th>lag3_데이터집단3_강우(C지역)</th>\n",
              "      <th>lag3_데이터집단3_강우(D지역)</th>\n",
              "      <th>lag3_데이터집단4_강우(A지역)</th>\n",
              "      <th>lag3_데이터집단4_강우(B지역)</th>\n",
              "      <th>lag3_데이터집단4_강우(C지역)</th>\n",
              "      <th>lag3_데이터집단4_강우(D지역)</th>\n",
              "      <th>lag3_데이터집단5_강우(A지역)</th>\n",
              "      <th>lag3_데이터집단5_강우(B지역)</th>\n",
              "      <th>lag3_데이터집단5_강우(C지역)</th>\n",
              "      <th>lag3_데이터집단5_강우(D지역)</th>\n",
              "      <th>lag3_데이터집단6_강우(A지역)</th>\n",
              "      <th>lag3_데이터집단6_강우(B지역)</th>\n",
              "      <th>lag3_데이터집단6_강우(C지역)</th>\n",
              "      <th>lag3_데이터집단6_강우(D지역)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.841637</td>\n",
              "      <td>-1.056500</td>\n",
              "      <td>-0.983152</td>\n",
              "      <td>-0.934386</td>\n",
              "      <td>-0.712692</td>\n",
              "      <td>-0.809595</td>\n",
              "      <td>-0.886461</td>\n",
              "      <td>-1.472248</td>\n",
              "      <td>-1.069682</td>\n",
              "      <td>-1.012258</td>\n",
              "      <td>-0.927517</td>\n",
              "      <td>-0.710539</td>\n",
              "      <td>-0.809595</td>\n",
              "      <td>-0.886461</td>\n",
              "      <td>-1.489093</td>\n",
              "      <td>-1.069682</td>\n",
              "      <td>-1.012258</td>\n",
              "      <td>-0.873637</td>\n",
              "      <td>-0.717134</td>\n",
              "      <td>-0.817334</td>\n",
              "      <td>-0.886461</td>\n",
              "      <td>-1.495082</td>\n",
              "      <td>-1.079422</td>\n",
              "      <td>-1.026774</td>\n",
              "      <td>-0.873637</td>\n",
              "      <td>-0.830143</td>\n",
              "      <td>-0.843068</td>\n",
              "      <td>-0.886461</td>\n",
              "      <td>-1.430240</td>\n",
              "      <td>-1.065010</td>\n",
              "      <td>-1.026774</td>\n",
              "      <td>-0.873637</td>\n",
              "      <td>-0.830143</td>\n",
              "      <td>-0.843068</td>\n",
              "      <td>-0.886461</td>\n",
              "      <td>-1.439777</td>\n",
              "      <td>-1.017052</td>\n",
              "      <td>-1.026774</td>\n",
              "      <td>-0.881985</td>\n",
              "      <td>-0.695770</td>\n",
              "      <td>-0.822802</td>\n",
              "      <td>-0.886461</td>\n",
              "      <td>-1.454281</td>\n",
              "      <td>-0.958907</td>\n",
              "      <td>-0.909183</td>\n",
              "      <td>-0.693856</td>\n",
              "      <td>-0.787988</td>\n",
              "      <td>-0.98739</td>\n",
              "      <td>-0.902843</td>\n",
              "      <td>-0.692329</td>\n",
              "      <td>-0.787988</td>\n",
              "      <td>-0.98739</td>\n",
              "      <td>-0.851463</td>\n",
              "      <td>-0.699475</td>\n",
              "      <td>-0.795502</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.851463</td>\n",
              "      <td>-0.809129</td>\n",
              "      <td>-0.820640</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.851463</td>\n",
              "      <td>-0.809129</td>\n",
              "      <td>-0.820640</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.859493</td>\n",
              "      <td>-0.681334</td>\n",
              "      <td>-0.800985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.825271</td>\n",
              "      <td>-1.058261</td>\n",
              "      <td>-0.983152</td>\n",
              "      <td>-0.917497</td>\n",
              "      <td>-0.712692</td>\n",
              "      <td>-0.809595</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.473277</td>\n",
              "      <td>-1.067914</td>\n",
              "      <td>-1.012258</td>\n",
              "      <td>-0.910481</td>\n",
              "      <td>-0.710539</td>\n",
              "      <td>-0.809595</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.487720</td>\n",
              "      <td>-1.067914</td>\n",
              "      <td>-1.012258</td>\n",
              "      <td>-0.855492</td>\n",
              "      <td>-0.717134</td>\n",
              "      <td>-0.817334</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.493707</td>\n",
              "      <td>-1.063454</td>\n",
              "      <td>-1.026774</td>\n",
              "      <td>-0.855492</td>\n",
              "      <td>-0.790995</td>\n",
              "      <td>-0.806740</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.431417</td>\n",
              "      <td>-1.048773</td>\n",
              "      <td>-1.026774</td>\n",
              "      <td>-0.855492</td>\n",
              "      <td>-0.790995</td>\n",
              "      <td>-0.806740</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.441754</td>\n",
              "      <td>-0.999933</td>\n",
              "      <td>-1.026774</td>\n",
              "      <td>-0.864008</td>\n",
              "      <td>-0.649239</td>\n",
              "      <td>-0.785648</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.455927</td>\n",
              "      <td>-0.958907</td>\n",
              "      <td>-0.909183</td>\n",
              "      <td>-0.693856</td>\n",
              "      <td>-0.787988</td>\n",
              "      <td>-0.98739</td>\n",
              "      <td>-0.902843</td>\n",
              "      <td>-0.692329</td>\n",
              "      <td>-0.787988</td>\n",
              "      <td>-0.98739</td>\n",
              "      <td>-0.851463</td>\n",
              "      <td>-0.699475</td>\n",
              "      <td>-0.795502</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.851463</td>\n",
              "      <td>-0.809129</td>\n",
              "      <td>-0.820640</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.851463</td>\n",
              "      <td>-0.809129</td>\n",
              "      <td>-0.820640</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.859493</td>\n",
              "      <td>-0.681334</td>\n",
              "      <td>-0.800985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.805016</td>\n",
              "      <td>-1.056500</td>\n",
              "      <td>-0.983152</td>\n",
              "      <td>-0.900608</td>\n",
              "      <td>-0.712692</td>\n",
              "      <td>-0.809595</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.474306</td>\n",
              "      <td>-1.052005</td>\n",
              "      <td>-1.012258</td>\n",
              "      <td>-0.893445</td>\n",
              "      <td>-0.710539</td>\n",
              "      <td>-0.809595</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.486347</td>\n",
              "      <td>-1.052005</td>\n",
              "      <td>-1.012258</td>\n",
              "      <td>-0.837347</td>\n",
              "      <td>-0.694442</td>\n",
              "      <td>-0.817334</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.492332</td>\n",
              "      <td>-1.047485</td>\n",
              "      <td>-1.026774</td>\n",
              "      <td>-0.837347</td>\n",
              "      <td>-0.790995</td>\n",
              "      <td>-0.788576</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.432594</td>\n",
              "      <td>-1.032537</td>\n",
              "      <td>-1.026774</td>\n",
              "      <td>-0.837347</td>\n",
              "      <td>-0.790995</td>\n",
              "      <td>-0.788576</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.443730</td>\n",
              "      <td>-0.982813</td>\n",
              "      <td>-1.026774</td>\n",
              "      <td>-0.846030</td>\n",
              "      <td>-0.649239</td>\n",
              "      <td>-0.767072</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.457572</td>\n",
              "      <td>-0.958907</td>\n",
              "      <td>-0.909183</td>\n",
              "      <td>-0.693856</td>\n",
              "      <td>-0.787988</td>\n",
              "      <td>-0.98739</td>\n",
              "      <td>-0.902843</td>\n",
              "      <td>-0.692329</td>\n",
              "      <td>-0.787988</td>\n",
              "      <td>-0.98739</td>\n",
              "      <td>-0.851463</td>\n",
              "      <td>-0.699475</td>\n",
              "      <td>-0.795502</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.851463</td>\n",
              "      <td>-0.809129</td>\n",
              "      <td>-0.820640</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.851463</td>\n",
              "      <td>-0.809129</td>\n",
              "      <td>-0.820640</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.859493</td>\n",
              "      <td>-0.681334</td>\n",
              "      <td>-0.800985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.774821</td>\n",
              "      <td>-1.040648</td>\n",
              "      <td>-0.983152</td>\n",
              "      <td>-0.883718</td>\n",
              "      <td>-0.712692</td>\n",
              "      <td>-0.809595</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.474306</td>\n",
              "      <td>-1.036096</td>\n",
              "      <td>-1.012258</td>\n",
              "      <td>-0.876409</td>\n",
              "      <td>-0.687945</td>\n",
              "      <td>-0.809595</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.484973</td>\n",
              "      <td>-1.036096</td>\n",
              "      <td>-1.012258</td>\n",
              "      <td>-0.819202</td>\n",
              "      <td>-0.649059</td>\n",
              "      <td>-0.780800</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.490957</td>\n",
              "      <td>-0.992483</td>\n",
              "      <td>-0.999278</td>\n",
              "      <td>-0.819202</td>\n",
              "      <td>-0.693122</td>\n",
              "      <td>-0.734085</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.433771</td>\n",
              "      <td>-0.976610</td>\n",
              "      <td>-0.999278</td>\n",
              "      <td>-0.819202</td>\n",
              "      <td>-0.693122</td>\n",
              "      <td>-0.734085</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.446366</td>\n",
              "      <td>-0.923847</td>\n",
              "      <td>-0.999278</td>\n",
              "      <td>-0.828053</td>\n",
              "      <td>-0.532912</td>\n",
              "      <td>-0.711342</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.458395</td>\n",
              "      <td>-0.958907</td>\n",
              "      <td>-0.909183</td>\n",
              "      <td>-0.693856</td>\n",
              "      <td>-0.787988</td>\n",
              "      <td>-0.98739</td>\n",
              "      <td>-0.902843</td>\n",
              "      <td>-0.692329</td>\n",
              "      <td>-0.787988</td>\n",
              "      <td>-0.98739</td>\n",
              "      <td>-0.851463</td>\n",
              "      <td>-0.699475</td>\n",
              "      <td>-0.795502</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.851463</td>\n",
              "      <td>-0.809129</td>\n",
              "      <td>-0.820640</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.851463</td>\n",
              "      <td>-0.809129</td>\n",
              "      <td>-0.820640</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.859493</td>\n",
              "      <td>-0.681334</td>\n",
              "      <td>-0.800985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.726655</td>\n",
              "      <td>-1.024797</td>\n",
              "      <td>-0.983152</td>\n",
              "      <td>-0.849939</td>\n",
              "      <td>-0.690495</td>\n",
              "      <td>-0.773121</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.474306</td>\n",
              "      <td>-0.981299</td>\n",
              "      <td>-0.984565</td>\n",
              "      <td>-0.842336</td>\n",
              "      <td>-0.642758</td>\n",
              "      <td>-0.773121</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.483600</td>\n",
              "      <td>-0.981299</td>\n",
              "      <td>-0.984565</td>\n",
              "      <td>-0.782912</td>\n",
              "      <td>-0.649059</td>\n",
              "      <td>-0.762533</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.490957</td>\n",
              "      <td>-0.937481</td>\n",
              "      <td>-0.958035</td>\n",
              "      <td>-0.782912</td>\n",
              "      <td>-0.634399</td>\n",
              "      <td>-0.697758</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.436125</td>\n",
              "      <td>-0.920684</td>\n",
              "      <td>-0.958035</td>\n",
              "      <td>-0.782912</td>\n",
              "      <td>-0.634399</td>\n",
              "      <td>-0.697758</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.449001</td>\n",
              "      <td>-0.864881</td>\n",
              "      <td>-0.958035</td>\n",
              "      <td>-0.792099</td>\n",
              "      <td>-0.463116</td>\n",
              "      <td>-0.674188</td>\n",
              "      <td>-0.891035</td>\n",
              "      <td>-1.460041</td>\n",
              "      <td>-0.958907</td>\n",
              "      <td>-0.892314</td>\n",
              "      <td>-0.693856</td>\n",
              "      <td>-0.787988</td>\n",
              "      <td>-0.98739</td>\n",
              "      <td>-0.885824</td>\n",
              "      <td>-0.692329</td>\n",
              "      <td>-0.787988</td>\n",
              "      <td>-0.98739</td>\n",
              "      <td>-0.833296</td>\n",
              "      <td>-0.699475</td>\n",
              "      <td>-0.795502</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.833296</td>\n",
              "      <td>-0.769959</td>\n",
              "      <td>-0.784291</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.833296</td>\n",
              "      <td>-0.769959</td>\n",
              "      <td>-0.784291</td>\n",
              "      <td>-1.001584</td>\n",
              "      <td>-0.841499</td>\n",
              "      <td>-0.634911</td>\n",
              "      <td>-0.763907</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   홍수사상번호       유입량  ...  lag3_데이터집단6_강우(C지역)  lag3_데이터집단6_강우(D지역)\n",
              "0       1 -0.841637  ...            -0.681334            -0.800985\n",
              "1       1 -0.825271  ...            -0.681334            -0.800985\n",
              "2       1 -0.805016  ...            -0.681334            -0.800985\n",
              "3       1 -0.774821  ...            -0.681334            -0.800985\n",
              "4       1 -0.726655  ...            -0.634911            -0.763907\n",
              "\n",
              "[5 rows x 68 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFA56yoIK1tC"
      },
      "source": [
        "def window_dataset(df,label=None,window_size=20):\n",
        "    if label is not None:\n",
        "        window_list=[]\n",
        "        label_list=[]\n",
        "        for i in range(df.shape[0]-window_size):\n",
        "            window_list.append(np.array(df[i:i+window_size]))\n",
        "            label_list.append(np.array(label.iloc[i+window_size]))\n",
        "\n",
        "        return np.array(window_list),np.array(label_list)\n",
        "    else:\n",
        "        window_list=[]\n",
        "        for i in range(df.shape[0]-window_size):\n",
        "            window_list.append(np.array(df[i:i+window_size]))\n",
        "        return np.array(window_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIhk9EVwK3-5",
        "outputId": "e5e57a9e-29bd-44cc-ba7b-4b4013a12a19"
      },
      "source": [
        "data[data['홍수사상번호']==26].index[0],data[data['홍수사상번호']==25].index[0],data[data['홍수사상번호']==24].index[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2865, 2762, 2668)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjeILDyJKTqo"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "lpca=PCA(n_components=30)\n",
        "data_pca=lpca.fit_transform(data.iloc[:,2:])\n",
        "\n",
        "label=data['유입량']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbIG_0k9LA1i"
      },
      "source": [
        "train_x=data_pca[:2668]\n",
        "valid_x=data_pca[:2762]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or0UubgILKyM",
        "outputId": "eb1d7b7f-1ac5-4c2b-cef1-a0e975a945e1"
      },
      "source": [
        "test=data_pca\n",
        "\n",
        "train_feature=train_x\n",
        "train_label=label[:2668]\n",
        "valid_feature=valid_x\n",
        "valid_label=label[:2762]\n",
        "\n",
        "train_feature, train_label=window_dataset(df=train_feature,label=train_label)\n",
        "valid_feature, valid_label=window_dataset(df=valid_feature,label=valid_label)\n",
        "test_feature=window_dataset(df=test)\n",
        "\n",
        "print(f\"train_feature.shape : {train_feature.shape}, train_label.shape : {train_label.shape}\")\n",
        "print(f\"valid_feature.shape : {valid_feature.shape}, valid_label.shape : {valid_label.shape}\")\n",
        "print(f\"test_feature.shape : {test_feature.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_feature.shape : (2648, 20, 30), train_label.shape : (2648,)\n",
            "valid_feature.shape : (2742, 20, 30), valid_label.shape : (2742,)\n",
            "test_feature.shape : (3005, 20, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dk7BhYPLYcm"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZS4MvitLkdq",
        "outputId": "6f14edc3-1899-4eba-d6c1-825bd2f6dcc2"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "    return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
        "\n",
        "def lstm(df,n_lstm):\n",
        "    model=keras.models.Sequential([\n",
        "        LSTM(n_lstm,input_shape=[df.shape[1],df.shape[2]],return_sequences=False,activation='tanh'),\n",
        "        Dense(1)\n",
        "        ])\n",
        "    model.compile(loss=root_mean_squared_error,\n",
        "                  optimizer='adam',\n",
        "                  metrics =[tf.keras.metrics.RootMeanSquaredError()])\n",
        "    return model\n",
        "\n",
        "params={'df':train_feature,\n",
        "        'n_lstm': 60}\n",
        "\n",
        "lstm_model=lstm(**params)\n",
        "\n",
        "lstm_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 60)                21840     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 61        \n",
            "=================================================================\n",
            "Total params: 21,901\n",
            "Trainable params: 21,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl9nTTbRLmYV",
        "outputId": "1be78384-3c8f-4a63-d78f-87e69f33b067"
      },
      "source": [
        "#model training\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('lstm_model_pca.h5',\n",
        "                                                monitor='val_root_mean_squared_error',\n",
        "                                                save_best_only=True)\n",
        "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "history = lstm_model.fit(train_feature, train_label, epochs=1000, \n",
        "       validation_data = (valid_feature, valid_label), verbose=1, batch_size=16,\n",
        "              callbacks = [checkpoint_cb, earlystopping_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "166/166 [==============================] - 5s 18ms/step - loss: 0.4061 - root_mean_squared_error: 0.4918 - val_loss: 0.1866 - val_root_mean_squared_error: 0.2530\n",
            "Epoch 2/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.1973 - root_mean_squared_error: 0.2152 - val_loss: 0.1371 - val_root_mean_squared_error: 0.1845\n",
            "Epoch 3/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.1588 - root_mean_squared_error: 0.1754 - val_loss: 0.1195 - val_root_mean_squared_error: 0.1594\n",
            "Epoch 4/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.1375 - root_mean_squared_error: 0.1519 - val_loss: 0.1110 - val_root_mean_squared_error: 0.1478\n",
            "Epoch 5/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.1218 - root_mean_squared_error: 0.1366 - val_loss: 0.0931 - val_root_mean_squared_error: 0.1270\n",
            "Epoch 6/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.1090 - root_mean_squared_error: 0.1228 - val_loss: 0.0914 - val_root_mean_squared_error: 0.1312\n",
            "Epoch 7/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.1013 - root_mean_squared_error: 0.1161 - val_loss: 0.0972 - val_root_mean_squared_error: 0.1328\n",
            "Epoch 8/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0968 - root_mean_squared_error: 0.1126 - val_loss: 0.0869 - val_root_mean_squared_error: 0.1236\n",
            "Epoch 9/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0928 - root_mean_squared_error: 0.1078 - val_loss: 0.0819 - val_root_mean_squared_error: 0.1150\n",
            "Epoch 10/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0881 - root_mean_squared_error: 0.1048 - val_loss: 0.0875 - val_root_mean_squared_error: 0.1251\n",
            "Epoch 11/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0837 - root_mean_squared_error: 0.0982 - val_loss: 0.0849 - val_root_mean_squared_error: 0.1264\n",
            "Epoch 12/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0821 - root_mean_squared_error: 0.0983 - val_loss: 0.0787 - val_root_mean_squared_error: 0.1170\n",
            "Epoch 13/1000\n",
            "166/166 [==============================] - 2s 15ms/step - loss: 0.0787 - root_mean_squared_error: 0.0947 - val_loss: 0.0717 - val_root_mean_squared_error: 0.1143\n",
            "Epoch 14/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0736 - root_mean_squared_error: 0.0920 - val_loss: 0.0673 - val_root_mean_squared_error: 0.1100\n",
            "Epoch 15/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0725 - root_mean_squared_error: 0.0902 - val_loss: 0.0704 - val_root_mean_squared_error: 0.1132\n",
            "Epoch 16/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0704 - root_mean_squared_error: 0.0894 - val_loss: 0.0673 - val_root_mean_squared_error: 0.1115\n",
            "Epoch 17/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0702 - root_mean_squared_error: 0.0884 - val_loss: 0.0655 - val_root_mean_squared_error: 0.1100\n",
            "Epoch 18/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0667 - root_mean_squared_error: 0.0857 - val_loss: 0.0685 - val_root_mean_squared_error: 0.1167\n",
            "Epoch 19/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0669 - root_mean_squared_error: 0.0856 - val_loss: 0.0660 - val_root_mean_squared_error: 0.1121\n",
            "Epoch 20/1000\n",
            "166/166 [==============================] - 2s 15ms/step - loss: 0.0658 - root_mean_squared_error: 0.0846 - val_loss: 0.0631 - val_root_mean_squared_error: 0.1089\n",
            "Epoch 21/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0610 - root_mean_squared_error: 0.0810 - val_loss: 0.0636 - val_root_mean_squared_error: 0.1073\n",
            "Epoch 22/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0611 - root_mean_squared_error: 0.0811 - val_loss: 0.0640 - val_root_mean_squared_error: 0.1085\n",
            "Epoch 23/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0640 - root_mean_squared_error: 0.0833 - val_loss: 0.0576 - val_root_mean_squared_error: 0.1061\n",
            "Epoch 24/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0600 - root_mean_squared_error: 0.0802 - val_loss: 0.0655 - val_root_mean_squared_error: 0.1124\n",
            "Epoch 25/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0601 - root_mean_squared_error: 0.0812 - val_loss: 0.0601 - val_root_mean_squared_error: 0.1103\n",
            "Epoch 26/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0572 - root_mean_squared_error: 0.0789 - val_loss: 0.0604 - val_root_mean_squared_error: 0.1087\n",
            "Epoch 27/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0595 - root_mean_squared_error: 0.0805 - val_loss: 0.0579 - val_root_mean_squared_error: 0.1089\n",
            "Epoch 28/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0572 - root_mean_squared_error: 0.0783 - val_loss: 0.0652 - val_root_mean_squared_error: 0.1118\n",
            "Epoch 29/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0564 - root_mean_squared_error: 0.0776 - val_loss: 0.0633 - val_root_mean_squared_error: 0.1057\n",
            "Epoch 30/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0551 - root_mean_squared_error: 0.0767 - val_loss: 0.0536 - val_root_mean_squared_error: 0.1044\n",
            "Epoch 31/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0562 - root_mean_squared_error: 0.0774 - val_loss: 0.0634 - val_root_mean_squared_error: 0.1087\n",
            "Epoch 32/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0554 - root_mean_squared_error: 0.0765 - val_loss: 0.0555 - val_root_mean_squared_error: 0.1034\n",
            "Epoch 33/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0508 - root_mean_squared_error: 0.0748 - val_loss: 0.0552 - val_root_mean_squared_error: 0.1061\n",
            "Epoch 34/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0527 - root_mean_squared_error: 0.0748 - val_loss: 0.0558 - val_root_mean_squared_error: 0.1025\n",
            "Epoch 35/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0528 - root_mean_squared_error: 0.0746 - val_loss: 0.0516 - val_root_mean_squared_error: 0.1041\n",
            "Epoch 36/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0528 - root_mean_squared_error: 0.0756 - val_loss: 0.0523 - val_root_mean_squared_error: 0.1064\n",
            "Epoch 37/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0513 - root_mean_squared_error: 0.0736 - val_loss: 0.0524 - val_root_mean_squared_error: 0.1033\n",
            "Epoch 38/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0522 - root_mean_squared_error: 0.0754 - val_loss: 0.0514 - val_root_mean_squared_error: 0.1037\n",
            "Epoch 39/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0492 - root_mean_squared_error: 0.0741 - val_loss: 0.0509 - val_root_mean_squared_error: 0.1001\n",
            "Epoch 40/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0498 - root_mean_squared_error: 0.0726 - val_loss: 0.0574 - val_root_mean_squared_error: 0.1029\n",
            "Epoch 41/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0511 - root_mean_squared_error: 0.0737 - val_loss: 0.0501 - val_root_mean_squared_error: 0.1011\n",
            "Epoch 42/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0482 - root_mean_squared_error: 0.0725 - val_loss: 0.0524 - val_root_mean_squared_error: 0.1004\n",
            "Epoch 43/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0507 - root_mean_squared_error: 0.0737 - val_loss: 0.0570 - val_root_mean_squared_error: 0.1077\n",
            "Epoch 44/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0497 - root_mean_squared_error: 0.0737 - val_loss: 0.0492 - val_root_mean_squared_error: 0.1000\n",
            "Epoch 45/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0482 - root_mean_squared_error: 0.0720 - val_loss: 0.0528 - val_root_mean_squared_error: 0.1016\n",
            "Epoch 46/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0477 - root_mean_squared_error: 0.0716 - val_loss: 0.0511 - val_root_mean_squared_error: 0.0976\n",
            "Epoch 47/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0470 - root_mean_squared_error: 0.0705 - val_loss: 0.0514 - val_root_mean_squared_error: 0.0998\n",
            "Epoch 48/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0491 - root_mean_squared_error: 0.0704 - val_loss: 0.0506 - val_root_mean_squared_error: 0.0994\n",
            "Epoch 49/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0463 - root_mean_squared_error: 0.0704 - val_loss: 0.0487 - val_root_mean_squared_error: 0.0990\n",
            "Epoch 50/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0465 - root_mean_squared_error: 0.0717 - val_loss: 0.0497 - val_root_mean_squared_error: 0.0990\n",
            "Epoch 51/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0470 - root_mean_squared_error: 0.0702 - val_loss: 0.0534 - val_root_mean_squared_error: 0.0990\n",
            "Epoch 52/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0468 - root_mean_squared_error: 0.0706 - val_loss: 0.0467 - val_root_mean_squared_error: 0.0995\n",
            "Epoch 53/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0462 - root_mean_squared_error: 0.0705 - val_loss: 0.0499 - val_root_mean_squared_error: 0.1013\n",
            "Epoch 54/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0473 - root_mean_squared_error: 0.0721 - val_loss: 0.0475 - val_root_mean_squared_error: 0.0954\n",
            "Epoch 55/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0468 - root_mean_squared_error: 0.0713 - val_loss: 0.0497 - val_root_mean_squared_error: 0.0955\n",
            "Epoch 56/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0455 - root_mean_squared_error: 0.0689 - val_loss: 0.0477 - val_root_mean_squared_error: 0.0970\n",
            "Epoch 57/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0458 - root_mean_squared_error: 0.0701 - val_loss: 0.0507 - val_root_mean_squared_error: 0.0968\n",
            "Epoch 58/1000\n",
            "166/166 [==============================] - 2s 15ms/step - loss: 0.0479 - root_mean_squared_error: 0.0711 - val_loss: 0.0526 - val_root_mean_squared_error: 0.1009\n",
            "Epoch 59/1000\n",
            "166/166 [==============================] - 2s 15ms/step - loss: 0.0451 - root_mean_squared_error: 0.0700 - val_loss: 0.0457 - val_root_mean_squared_error: 0.0977\n",
            "Epoch 60/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0441 - root_mean_squared_error: 0.0667 - val_loss: 0.0468 - val_root_mean_squared_error: 0.0978\n",
            "Epoch 61/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0458 - root_mean_squared_error: 0.0695 - val_loss: 0.0471 - val_root_mean_squared_error: 0.0978\n",
            "Epoch 62/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0460 - root_mean_squared_error: 0.0704 - val_loss: 0.0454 - val_root_mean_squared_error: 0.0931\n",
            "Epoch 63/1000\n",
            "166/166 [==============================] - 2s 15ms/step - loss: 0.0436 - root_mean_squared_error: 0.0684 - val_loss: 0.0455 - val_root_mean_squared_error: 0.0974\n",
            "Epoch 64/1000\n",
            "166/166 [==============================] - 2s 15ms/step - loss: 0.0433 - root_mean_squared_error: 0.0698 - val_loss: 0.0470 - val_root_mean_squared_error: 0.0978\n",
            "Epoch 65/1000\n",
            "166/166 [==============================] - 2s 15ms/step - loss: 0.0426 - root_mean_squared_error: 0.0680 - val_loss: 0.0454 - val_root_mean_squared_error: 0.0974\n",
            "Epoch 66/1000\n",
            "166/166 [==============================] - 2s 15ms/step - loss: 0.0442 - root_mean_squared_error: 0.0690 - val_loss: 0.0469 - val_root_mean_squared_error: 0.0981\n",
            "Epoch 67/1000\n",
            "166/166 [==============================] - 2s 15ms/step - loss: 0.0417 - root_mean_squared_error: 0.0666 - val_loss: 0.0448 - val_root_mean_squared_error: 0.0913\n",
            "Epoch 68/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0425 - root_mean_squared_error: 0.0667 - val_loss: 0.0443 - val_root_mean_squared_error: 0.0924\n",
            "Epoch 69/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0431 - root_mean_squared_error: 0.0665 - val_loss: 0.0454 - val_root_mean_squared_error: 0.0953\n",
            "Epoch 70/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0422 - root_mean_squared_error: 0.0666 - val_loss: 0.0471 - val_root_mean_squared_error: 0.0951\n",
            "Epoch 71/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0426 - root_mean_squared_error: 0.0667 - val_loss: 0.0471 - val_root_mean_squared_error: 0.0939\n",
            "Epoch 72/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0427 - root_mean_squared_error: 0.0656 - val_loss: 0.0486 - val_root_mean_squared_error: 0.0967\n",
            "Epoch 73/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0430 - root_mean_squared_error: 0.0674 - val_loss: 0.0477 - val_root_mean_squared_error: 0.0924\n",
            "Epoch 74/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0410 - root_mean_squared_error: 0.0668 - val_loss: 0.0432 - val_root_mean_squared_error: 0.0929\n",
            "Epoch 75/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0421 - root_mean_squared_error: 0.0642 - val_loss: 0.0435 - val_root_mean_squared_error: 0.0929\n",
            "Epoch 76/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0411 - root_mean_squared_error: 0.0666 - val_loss: 0.0500 - val_root_mean_squared_error: 0.0948\n",
            "Epoch 77/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0419 - root_mean_squared_error: 0.0655 - val_loss: 0.0435 - val_root_mean_squared_error: 0.0937\n",
            "Epoch 78/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0405 - root_mean_squared_error: 0.0645 - val_loss: 0.0478 - val_root_mean_squared_error: 0.0978\n",
            "Epoch 79/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0420 - root_mean_squared_error: 0.0659 - val_loss: 0.0441 - val_root_mean_squared_error: 0.0920\n",
            "Epoch 80/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0405 - root_mean_squared_error: 0.0642 - val_loss: 0.0425 - val_root_mean_squared_error: 0.0940\n",
            "Epoch 81/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0397 - root_mean_squared_error: 0.0650 - val_loss: 0.0451 - val_root_mean_squared_error: 0.0930\n",
            "Epoch 82/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0416 - root_mean_squared_error: 0.0663 - val_loss: 0.0466 - val_root_mean_squared_error: 0.0944\n",
            "Epoch 83/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0418 - root_mean_squared_error: 0.0653 - val_loss: 0.0488 - val_root_mean_squared_error: 0.0950\n",
            "Epoch 84/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0422 - root_mean_squared_error: 0.0646 - val_loss: 0.0454 - val_root_mean_squared_error: 0.0903\n",
            "Epoch 85/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0405 - root_mean_squared_error: 0.0655 - val_loss: 0.0427 - val_root_mean_squared_error: 0.0911\n",
            "Epoch 86/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0408 - root_mean_squared_error: 0.0655 - val_loss: 0.0415 - val_root_mean_squared_error: 0.0901\n",
            "Epoch 87/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0404 - root_mean_squared_error: 0.0638 - val_loss: 0.0402 - val_root_mean_squared_error: 0.0919\n",
            "Epoch 88/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0391 - root_mean_squared_error: 0.0640 - val_loss: 0.0473 - val_root_mean_squared_error: 0.0979\n",
            "Epoch 89/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0381 - root_mean_squared_error: 0.0641 - val_loss: 0.0402 - val_root_mean_squared_error: 0.0891\n",
            "Epoch 90/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0384 - root_mean_squared_error: 0.0613 - val_loss: 0.0454 - val_root_mean_squared_error: 0.0914\n",
            "Epoch 91/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0388 - root_mean_squared_error: 0.0625 - val_loss: 0.0406 - val_root_mean_squared_error: 0.0914\n",
            "Epoch 92/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0371 - root_mean_squared_error: 0.0636 - val_loss: 0.0418 - val_root_mean_squared_error: 0.0920\n",
            "Epoch 93/1000\n",
            "166/166 [==============================] - 2s 15ms/step - loss: 0.0374 - root_mean_squared_error: 0.0628 - val_loss: 0.0436 - val_root_mean_squared_error: 0.0916\n",
            "Epoch 94/1000\n",
            "166/166 [==============================] - 2s 14ms/step - loss: 0.0388 - root_mean_squared_error: 0.0633 - val_loss: 0.0438 - val_root_mean_squared_error: 0.0911\n",
            "Epoch 95/1000\n",
            "166/166 [==============================] - 3s 15ms/step - loss: 0.0397 - root_mean_squared_error: 0.0642 - val_loss: 0.0427 - val_root_mean_squared_error: 0.0913\n",
            "Epoch 96/1000\n",
            "166/166 [==============================] - 2s 15ms/step - loss: 0.0387 - root_mean_squared_error: 0.0619 - val_loss: 0.0419 - val_root_mean_squared_error: 0.0919\n",
            "Epoch 97/1000\n",
            "166/166 [==============================] - 2s 15ms/step - loss: 0.0378 - root_mean_squared_error: 0.0628 - val_loss: 0.0431 - val_root_mean_squared_error: 0.0910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3vrhMj8LohN",
        "outputId": "8158bef9-0b72-4992-f818-be3259c2358b"
      },
      "source": [
        "lstm_model.load_weights('/content/lstm_model_pca.h5')\n",
        "pred = lstm_model.predict(valid_feature)\n",
        "\n",
        "## mean 더하고 std 곱하기\n",
        "scaled_pred=(pred*std)+mean\n",
        "scaled_pred=[x[0] if x[0]>0 else 0 for x in scaled_pred]\n",
        "scaled_test_label=(valid_label*std)+mean\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "rmse = mean_squared_error(scaled_test_label,scaled_pred)**0.5\n",
        "rmse "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151.5710491983212"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "BpMM6agrLroY",
        "outputId": "780af921-d37d-46b3-9706-97f538e9e881"
      },
      "source": [
        "pred=lstm_model.predict(test_feature)\n",
        "pred=(pred*std)+mean\n",
        "pred=[x[0] if x[0]>0 else 0 for x in pred][-160:]\n",
        "\n",
        "submit_lstm=submit.copy()\n",
        "submit_lstm['유입량']=pred\n",
        "submit_lstm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>홍수사상번호</th>\n",
              "      <th>연</th>\n",
              "      <th>월</th>\n",
              "      <th>일</th>\n",
              "      <th>시간</th>\n",
              "      <th>유입량</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2891</th>\n",
              "      <td>26</td>\n",
              "      <td>2018</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>427.081055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2892</th>\n",
              "      <td>26</td>\n",
              "      <td>2018</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>148.893921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2893</th>\n",
              "      <td>26</td>\n",
              "      <td>2018</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>182.546387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2894</th>\n",
              "      <td>26</td>\n",
              "      <td>2018</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>267.955078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2895</th>\n",
              "      <td>26</td>\n",
              "      <td>2018</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>356.224609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      홍수사상번호     연  월  일  시간         유입량\n",
              "2891      26  2018  7  1   6  427.081055\n",
              "2892      26  2018  7  1   7  148.893921\n",
              "2893      26  2018  7  1   8  182.546387\n",
              "2894      26  2018  7  1   9  267.955078\n",
              "2895      26  2018  7  1  10  356.224609"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKJawh_iMxxQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}