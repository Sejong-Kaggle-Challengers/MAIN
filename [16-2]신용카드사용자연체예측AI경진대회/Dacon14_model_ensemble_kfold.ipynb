{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train = train.drop(['index'], axis=1)\n",
    "train.fillna('NAN', inplace=True) \n",
    "train['occyp_type'].loc[(train.occyp_type == 'NAN')&(train.DAYS_EMPLOYED > 0)]='Unemployed'\n",
    "\n",
    "train.fillna('NAN', inplace=True) \n",
    "train['occyp_type'].loc[(train.occyp_type == 'NAN')&(train.DAYS_EMPLOYED < 0)]='Missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test = test.drop(['index'], axis=1)\n",
    "test.fillna('NAN', inplace=True)\n",
    "test['occyp_type'].loc[(test.occyp_type == 'NAN')&(test.DAYS_EMPLOYED > 0)]='Unemployed'\n",
    "test['occyp_type'].loc[(test.occyp_type == 'NAN')&(test.DAYS_EMPLOYED < 0)]='Missing'\n",
    "\n",
    "submit = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_col = []\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == 'object':\n",
    "        object_col.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(train.loc[:,object_col])\n",
    "\n",
    "\n",
    "train_onehot_df = pd.DataFrame(enc.transform(train.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "train.drop(object_col, axis=1, inplace=True)\n",
    "train = pd.concat([train, train_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_onehot_df = pd.DataFrame(enc.transform(test.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "test.drop(object_col, axis=1, inplace=True)\n",
    "test = pd.concat([test, test_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds=[]\n",
    "for train_idx, valid_idx in skf.split(train, train['credit']):\n",
    "    folds.append((train_idx, valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================1============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.652377\tvalid_1's multi_logloss: 0.752522\n",
      "[200]\ttraining's multi_logloss: 0.56559\tvalid_1's multi_logloss: 0.737156\n",
      "[300]\ttraining's multi_logloss: 0.501921\tvalid_1's multi_logloss: 0.731843\n",
      "Early stopping, best iteration is:\n",
      "[348]\ttraining's multi_logloss: 0.475822\tvalid_1's multi_logloss: 0.729304\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.646476\tvalid_1's multi_logloss: 0.764955\n",
      "[200]\ttraining's multi_logloss: 0.560614\tvalid_1's multi_logloss: 0.751681\n",
      "[300]\ttraining's multi_logloss: 0.497532\tvalid_1's multi_logloss: 0.748007\n",
      "Early stopping, best iteration is:\n",
      "[281]\ttraining's multi_logloss: 0.508566\tvalid_1's multi_logloss: 0.747717\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.652042\tvalid_1's multi_logloss: 0.758665\n",
      "[200]\ttraining's multi_logloss: 0.560771\tvalid_1's multi_logloss: 0.743359\n",
      "Early stopping, best iteration is:\n",
      "[246]\ttraining's multi_logloss: 0.529839\tvalid_1's multi_logloss: 0.74126\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.648049\tvalid_1's multi_logloss: 0.755495\n",
      "[200]\ttraining's multi_logloss: 0.560137\tvalid_1's multi_logloss: 0.739883\n",
      "[300]\ttraining's multi_logloss: 0.497795\tvalid_1's multi_logloss: 0.734204\n",
      "Early stopping, best iteration is:\n",
      "[309]\ttraining's multi_logloss: 0.493086\tvalid_1's multi_logloss: 0.733839\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[100]\ttraining's multi_logloss: 0.650986\tvalid_1's multi_logloss: 0.755168\n",
      "[200]\ttraining's multi_logloss: 0.565819\tvalid_1's multi_logloss: 0.740535\n",
      "[300]\ttraining's multi_logloss: 0.502856\tvalid_1's multi_logloss: 0.736778\n",
      "Early stopping, best iteration is:\n",
      "[323]\ttraining's multi_logloss: 0.490989\tvalid_1's multi_logloss: 0.736467\n",
      "================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "lgb_models={}\n",
    "for fold in range(5):\n",
    "    print(f'===================================={fold+1}============================================')\n",
    "    train_idx, valid_idx = folds[fold]\n",
    "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
    "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values \n",
    "    lgb = LGBMClassifier(n_estimators=1000)\n",
    "    lgb.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
    "            early_stopping_rounds=30,\n",
    "           verbose=100)\n",
    "    lgb_models[fold]=lgb\n",
    "    print(f'================================================================================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================1============================================\n",
      "[0]\tvalidation_0-mlogloss:0.97436\tvalidation_1-mlogloss:0.97758\n",
      "[100]\tvalidation_0-mlogloss:0.56747\tvalidation_1-mlogloss:0.73381\n",
      "[200]\tvalidation_0-mlogloss:0.44779\tvalidation_1-mlogloss:0.72234\n",
      "[211]\tvalidation_0-mlogloss:0.43764\tvalidation_1-mlogloss:0.72251\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n",
      "[0]\tvalidation_0-mlogloss:0.97304\tvalidation_1-mlogloss:0.97925\n",
      "[100]\tvalidation_0-mlogloss:0.56072\tvalidation_1-mlogloss:0.74882\n",
      "[200]\tvalidation_0-mlogloss:0.44335\tvalidation_1-mlogloss:0.74027\n",
      "[235]\tvalidation_0-mlogloss:0.41306\tvalidation_1-mlogloss:0.74266\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n",
      "[0]\tvalidation_0-mlogloss:0.97442\tvalidation_1-mlogloss:0.97858\n",
      "[100]\tvalidation_0-mlogloss:0.56273\tvalidation_1-mlogloss:0.74339\n",
      "[200]\tvalidation_0-mlogloss:0.44721\tvalidation_1-mlogloss:0.73763\n",
      "[204]\tvalidation_0-mlogloss:0.44292\tvalidation_1-mlogloss:0.73735\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n",
      "[0]\tvalidation_0-mlogloss:0.97382\tvalidation_1-mlogloss:0.97803\n",
      "[100]\tvalidation_0-mlogloss:0.56483\tvalidation_1-mlogloss:0.73918\n",
      "[200]\tvalidation_0-mlogloss:0.44943\tvalidation_1-mlogloss:0.73279\n",
      "[219]\tvalidation_0-mlogloss:0.43177\tvalidation_1-mlogloss:0.73394\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n",
      "[0]\tvalidation_0-mlogloss:0.97453\tvalidation_1-mlogloss:0.97726\n",
      "[100]\tvalidation_0-mlogloss:0.56257\tvalidation_1-mlogloss:0.73905\n",
      "[180]\tvalidation_0-mlogloss:0.46179\tvalidation_1-mlogloss:0.73390\n",
      "================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_models={}\n",
    "for fold in range(5):\n",
    "    print(f'===================================={fold+1}============================================')\n",
    "    train_idx, valid_idx = folds[fold]\n",
    "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
    "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values\n",
    "    params={\n",
    "    'objective':'multi:softprob',\n",
    "    'random_state':71,\n",
    "    'n_estimators':1000\n",
    "    }\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric = 'mlogloss',early_stopping_rounds=30, verbose=100)\n",
    "    xgb_models[fold]=model\n",
    "    print(f'================================================================================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================1============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    7.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    9.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   13.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   22.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_models={}\n",
    "for fold in range(5):\n",
    "    print(f'===================================={fold+1}============================================')\n",
    "    train_idx, valid_idx = folds[fold]\n",
    "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
    "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values\n",
    "    params={'n_estimators':1000,'random_state':71,'criterion':'gini','verbose':1,'class_weight':'balanced','n_jobs':-1,'oob_score':True}\n",
    "    model=RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    rf_models[fold]=model\n",
    "    print(f'================================================================================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================1============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   23.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   25.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   19.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   24.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   24.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_models={}\n",
    "for fold in range(5):\n",
    "    print(f'===================================={fold+1}============================================')\n",
    "    train_idx, valid_idx = folds[fold]\n",
    "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
    "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values\n",
    "    params={'gamma':'auto','probability':True,'random_state':71,'class_weight':'balanced','kernel':'poly','shrinking':True,'verbose':True}\n",
    "    svc_model=SVC(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    svc_models[fold]=model\n",
    "    print(f'================================================================================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "submit.iloc[:,1:]=0\n",
    "for fold in range(5):\n",
    "    submit.iloc[:,1:] += (lgb_models[fold].predict_proba(test)/20)\n",
    "    submit.iloc[:,1:] += (xgb_models[fold].predict_proba(test)/20)\n",
    "    submit.iloc[:,1:] += (rf_models[fold].predict_proba(test)/20)\n",
    "    submit.iloc[:,1:] += (svc_models[fold].predict_proba(test)/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26457</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.144719</td>\n",
       "      <td>0.809268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26458</td>\n",
       "      <td>0.225745</td>\n",
       "      <td>0.273219</td>\n",
       "      <td>0.501036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26459</td>\n",
       "      <td>0.045184</td>\n",
       "      <td>0.095037</td>\n",
       "      <td>0.859780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26460</td>\n",
       "      <td>0.087023</td>\n",
       "      <td>0.096783</td>\n",
       "      <td>0.816194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26461</td>\n",
       "      <td>0.091198</td>\n",
       "      <td>0.164841</td>\n",
       "      <td>0.743961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>36452</td>\n",
       "      <td>0.122803</td>\n",
       "      <td>0.297256</td>\n",
       "      <td>0.579941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>36453</td>\n",
       "      <td>0.207766</td>\n",
       "      <td>0.428965</td>\n",
       "      <td>0.363269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>36454</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.052253</td>\n",
       "      <td>0.935366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>36455</td>\n",
       "      <td>0.305808</td>\n",
       "      <td>0.263339</td>\n",
       "      <td>0.430852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>36456</td>\n",
       "      <td>0.091264</td>\n",
       "      <td>0.275985</td>\n",
       "      <td>0.632751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index         0         1         2\n",
       "0     26457  0.046012  0.144719  0.809268\n",
       "1     26458  0.225745  0.273219  0.501036\n",
       "2     26459  0.045184  0.095037  0.859780\n",
       "3     26460  0.087023  0.096783  0.816194\n",
       "4     26461  0.091198  0.164841  0.743961\n",
       "...     ...       ...       ...       ...\n",
       "9995  36452  0.122803  0.297256  0.579941\n",
       "9996  36453  0.207766  0.428965  0.363269\n",
       "9997  36454  0.012381  0.052253  0.935366\n",
       "9998  36455  0.305808  0.263339  0.430852\n",
       "9999  36456  0.091264  0.275985  0.632751\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('20210518_ensemble.csv', index=False) #0.7044283413 모델이 중요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
